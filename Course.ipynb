{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 663
        },
        "id": "-SO0u4g5IL7r",
        "outputId": "e964b2d4-f39b-455f-f628-38087ea4d783"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://5790f9a5d6bb3d770f.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://5790f9a5d6bb3d770f.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "!pip install --upgrade -q langchain langchain-community langchain-google-genai faiss-cpu pypdf python-pptx pandas==2.2.2 openpyxl python-docx gradio\n",
        "\n",
        "import os\n",
        "import google.generativeai as genai\n",
        "import gradio as gr\n",
        "import glob\n",
        "import pandas as pd\n",
        "from docx import Document\n",
        "from pptx import Presentation\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from google.colab import userdata\n",
        "from google.colab import drive\n",
        "import shutil\n",
        "\n",
        "# Set API Key\n",
        "os.environ['GOOGLE_API_KEY'] = userdata.get('GOOGLE_API_KEY')\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define the folder path containing documents (Modify as per your Drive structure)\n",
        "DOCUMENTS_FOLDER_PATH = \"/content/drive/My Drive/Agentic AI Assignment/\"\n",
        "\n",
        "vectorstore_path = \"/content/drive/My Drive/Agentic AI Assignment/vectorstore\"  # Modify this path as needed\n",
        "\n",
        "# Delete the existing vectorstore folder if it exists\n",
        "if os.path.exists(vectorstore_path):\n",
        "    shutil.rmtree(vectorstore_path)  # Removes all old vector data\n",
        "    print(\"‚úÖ Old vectorstore deleted successfully.\")\n",
        "\n",
        "# Function to extract text from different document types\n",
        "def extract_text_from_file(file_path):\n",
        "    \"\"\"Extracts text from PDF, DOCX, PPTX, and XLSX files.\"\"\"\n",
        "    text = \"\"\n",
        "\n",
        "    if file_path.endswith(\".pdf\"):\n",
        "        loader = PyPDFLoader(file_path)\n",
        "        documents = loader.load()\n",
        "        text = \"\\n\".join([doc.page_content for doc in documents])\n",
        "\n",
        "    elif file_path.endswith(\".docx\"):\n",
        "        doc = Document(file_path)\n",
        "        text = \"\\n\".join([para.text for para in doc.paragraphs])\n",
        "\n",
        "    elif file_path.endswith(\".ppt\") or file_path.endswith(\".pptx\"):\n",
        "        presentation = Presentation(file_path)\n",
        "        text_list = []\n",
        "        for slide in presentation.slides:\n",
        "          for shape in slide.shapes:\n",
        "            if hasattr(shape, \"text\") and shape.text.strip():  # Ensure shape has text\n",
        "                text_list.append(shape.text.strip())  # Append clean text\n",
        "        text = \"\\n\".join(text_list)\n",
        "\n",
        "    elif file_path.endswith(\".xls\") or file_path.endswith(\".xlsx\"):\n",
        "        df = pd.read_excel(file_path)\n",
        "        text = df.to_string()  # Convert entire spreadsheet to string\n",
        "\n",
        "    return text.strip()\n",
        "\n",
        "# Function to load and process all supported files from the given folder\n",
        "def load_and_process_documents(folder_path):\n",
        "    \"\"\"Loads and processes all PDFs, DOCX, PPTX, and XLSX files from the folder.\"\"\"\n",
        "    all_texts = []\n",
        "    supported_formats = [\"pdf\", \"docx\", \"ppt\", \"pptx\", \"xls\", \"xlsx\"]\n",
        "    files = sum([glob.glob(f\"{folder_path}/**/*.{ext}\", recursive=True) for ext in supported_formats], [])\n",
        "\n",
        "    if not files:\n",
        "        raise ValueError(\"‚ö†Ô∏è No supported files found in the specified folder!\")\n",
        "\n",
        "    for file in files:\n",
        "        extracted_text = extract_text_from_file(file)\n",
        "        if extracted_text:\n",
        "            all_texts.append(extracted_text)\n",
        "\n",
        "    # Split documents into chunks for better processing\n",
        "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
        "    docs = text_splitter.create_documents(all_texts)\n",
        "\n",
        "    # Create vector embeddings\n",
        "    embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-V2\")\n",
        "    vectorstore = FAISS.from_documents(docs, embeddings)\n",
        "\n",
        "    return vectorstore\n",
        "\n",
        "# Load and process documents at startup\n",
        "vectorstore = load_and_process_documents(DOCUMENTS_FOLDER_PATH)\n",
        "\n",
        "# Function to handle user queries\n",
        "def ask_question(query):\n",
        "    if not vectorstore:\n",
        "        return \"‚ö†Ô∏è No documents available. Please check the Drive folder and restart the application.\"\n",
        "\n",
        "    llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash-exp\")\n",
        "    qa = RetrievalQA.from_chain_type(llm, chain_type=\"stuff\", retriever=vectorstore.as_retriever())\n",
        "\n",
        "    answer = qa.run(query)\n",
        "    return f\"„Äå ‚ú¶ ‚öôÔ∏èAI ‚ú¶ „Äç: {answer}\"\n",
        "\n",
        "# Gradio Interface\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"<h2 style='text-align: center;  color: blue;'># „Äå ‚ú¶ ‚öôÔ∏èAI-Powered Course Management ‚ú¶ „Äç</h2>\")\n",
        "    gr.Markdown(\"This system is preloaded with PDF, Word, Powerpoint and Excel files regarding Human Computer Interaction course from Google Drive. Ask any question based on them.\")\n",
        "\n",
        "    query_input = gr.Textbox(label=\"Ask a question\")\n",
        "    submit_button = gr.Button(\"üí¨ Get Answer\")\n",
        "    output_text = gr.Textbox(label=\"AI Response\", interactive=False)\n",
        "\n",
        "    submit_button.click(ask_question, inputs=[query_input], outputs=[output_text])\n",
        "\n",
        "# Launch the interface\n",
        "demo.launch()\n"
      ]
    }
  ]
}